PRE: 

У нас есть два очень объемных лога формата jsonl: 
{"log_level": "DEBUG", "timestamp": "2000-01-01 00:00:00", "message": "smthng"}


TASK:

Надо их объеденить, сортируя по таймстампу.


RES:

Версия 1 очень жадна до RAM, один прогон на двух гигабайтных файлах может съесть ~10ГиБ. 

А все потому, что скрипт читает оба файла в память, там сортирует и потом сбрасывает все в выходной файл.
