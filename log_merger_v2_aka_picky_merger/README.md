PRE: 

У нас есть два очень объемных лога формата jsonl: 
{"log_level": "DEBUG", "timestamp": "2000-01-01 00:00:00", "message": "smthng"}


TASK:

Надо их объеденить, сортируя по таймстампу.


RES:

Версия 2 почти не требует RAM, один прогон на двух гигабайтных файлах может съесть ~20МиБ. 

А все потому, что скрипт читает оба файла по одной строчке, сравнивает их и потом записывает более ранюю.
И так пока не дойдет до конца одного из файлов, после чего просто дописывает оставшиеся строчки в выходной файл.
